{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from data_collection.data_collector import DataCollector\n",
    "\n",
    "import chess\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_collector = DataCollector(username=\"Hikaru\")  # Create an instance of DataCollector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_collector.get_data()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = zip(*data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "457599"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/22/1d7034ld4r9c2036tqjpn91c0000gn/T/ipykernel_46885/3548121009.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:257.)\n",
      "  x_train_tensors = torch.tensor(x_train, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "x_train_tensors = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train_tensors = torch.tensor(y_train, dtype=torch.long)\n",
    "x_test_tensors = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test_tensors = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 8*8\n",
    "input_size = 8*8*12\n",
    "\n",
    "model = nn.Sequential(\n",
    "    # Convolutional layers\n",
    "    nn.Conv2d(in_channels=12, out_channels=32, kernel_size=3, stride=1, padding=1),  # (12,8,8) -> (32,8,8)\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),  # (32,8,8) -> (64,8,8)\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(.2),\n",
    "    nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),  # (64,8,8) -> (128,8,8)\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),  # Reduce spatial dimensions from 8x8 to 4x4\n",
    "\n",
    "    # Flatten the output from conv layers\n",
    "    nn.Flatten(),  # Output shape: (batch_size, 128 * 4 * 4) = (batch_size, 2048)\n",
    "\n",
    "    # Fully connected layers\n",
    "    nn.Linear(128 * 4 * 4, 512),\n",
    "    nn.Dropout(.3),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, n_classes)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_accuracy(output, y, N):\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    correct = pred.eq(y.view_as(pred)).sum().item()\n",
    "    return correct / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TensorDataset(x_train_tensors, y_train_tensors)\n",
    "valid_set = TensorDataset(x_test_tensors, y_test_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_N = len(train_loader.dataset)\n",
    "valid_N = len(valid_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        output = model(x)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss = loss_function(output, y)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss += batch_loss.item()\n",
    "        accuracy += get_batch_accuracy(output, y, train_N)\n",
    "    print('Train - Loss: {:.4f} Accuracy: {:.4f}'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in valid_loader:\n",
    "            output = model(x)\n",
    "\n",
    "            loss += loss_function(output, y).item()\n",
    "            accuracy += get_batch_accuracy(output, y, valid_N)\n",
    "    print('Valid - Loss: {:.4f} Accuracy: {:.4f}'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train - Loss: 57817.8011 Accuracy: 0.2939\n",
      "Valid - Loss: 10931.7975 Accuracy: 0.4030\n",
      "Epoch: 1\n",
      "Train - Loss: 44682.8344 Accuracy: 0.3886\n",
      "Valid - Loss: 9986.0411 Accuracy: 0.4183\n",
      "Epoch: 2\n",
      "Train - Loss: 42120.9007 Accuracy: 0.4034\n",
      "Valid - Loss: 9698.5490 Accuracy: 0.4227\n",
      "Epoch: 3\n",
      "Train - Loss: 40895.7784 Accuracy: 0.4117\n",
      "Valid - Loss: 9585.1376 Accuracy: 0.4258\n",
      "Epoch: 4\n",
      "Train - Loss: 40137.0994 Accuracy: 0.4175\n",
      "Valid - Loss: 9440.3701 Accuracy: 0.4269\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('Epoch: {}'.format(epoch))\n",
    "    train()\n",
    "    validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fen_to_tensor(fen: str) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert a FEN position into an 8x8x12 torch tensor.\n",
    "    \n",
    "    The 12 channels represent:\n",
    "      Channel 0: White Pawn\n",
    "      Channel 1: White Knight\n",
    "      Channel 2: White Bishop\n",
    "      Channel 3: White Rook\n",
    "      Channel 4: White Queen\n",
    "      Channel 5: White King\n",
    "      Channel 6: Black Pawn\n",
    "      Channel 7: Black Knight\n",
    "      Channel 8: Black Bishop\n",
    "      Channel 9: Black Rook\n",
    "      Channel 10: Black Queen\n",
    "      Channel 11: Black King\n",
    "\n",
    "    Empty squares are 0, and the presence of a piece is indicated by 1.\n",
    "    \"\"\"\n",
    "    board = chess.Board(fen)\n",
    "    # Initialize an 8x8x12 array of zeros.\n",
    "    board_array = np.zeros((8, 8, 12), dtype=np.float32)\n",
    "    \n",
    "    # Iterate over all 64 squares.\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece is None:\n",
    "            continue\n",
    "        \n",
    "        # chess.square_rank returns 0 for rank 1, ..., 7 for rank 8.\n",
    "        # We want row 0 to represent rank 8 and row 7 to represent rank 1.\n",
    "        row = 7 - chess.square_rank(square)\n",
    "        col = chess.square_file(square)\n",
    "        \n",
    "        # Determine the channel.\n",
    "        # piece.piece_type: Pawn=1, Knight=2, Bishop=3, Rook=4, Queen=5, King=6.\n",
    "        # White pieces go to channels 0-5, black pieces to channels 6-11.\n",
    "        piece_type = piece.piece_type\n",
    "        if piece.color:  # White piece\n",
    "            channel = piece_type - 1\n",
    "        else:  # Black piece\n",
    "            channel = piece_type - 1 + 6\n",
    "        \n",
    "        board_array[row, col, channel] = 1.0\n",
    "\n",
    "    # Convert the numpy array to a torch tensor.\n",
    "    tensor_board = torch.tensor(board_array, dtype=torch.float32)\n",
    "    \n",
    "    tensor_board = np.transpose(tensor_board, (2, 0, 1))\n",
    "    return tensor_board\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "fen_str = \"8/5p2/2Rp1pkp/4p3/4P3/2pr3P/5PP1/6K1 b - - 5 28\"\n",
    "tensor_board = fen_to_tensor(fen_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value: 0.6800079345703125 at c6\n",
      "Max value: 0.1525385081768036 at g1\n",
      "Max value: 0.04776259511709213 at g2\n"
     ]
    }
   ],
   "source": [
    "tensor_board = tensor_board.unsqueeze(0)\n",
    "prediction = softmaxed_tensor = F.softmax(model(tensor_board), dim=1)\n",
    "matrix = prediction.view(8, 8)  \n",
    "torch.set_printoptions(precision=3, sci_mode=False)\n",
    "\n",
    "# Flatten the tensor\n",
    "flattened_matrix = matrix.flatten()\n",
    "\n",
    "# Find the top 3 maximum values and their indices (flattened)\n",
    "top_k = torch.topk(flattened_matrix, k=3)\n",
    "\n",
    "# Get the values and indices of the top 3 maximum values\n",
    "max_values = top_k.values\n",
    "max_indices = top_k.indices\n",
    "\n",
    "# Convert the flattened indices to 2D indices using torch.div and torch.remainder\n",
    "rows = torch.div(max_indices, matrix.size(1), rounding_mode='floor')  # Integer division (row)\n",
    "cols = torch.remainder(max_indices, matrix.size(1))  # Remainder (column)\n",
    "\n",
    "# Print the top 3 maximum values and their locations in chess notation\n",
    "for i in range(3):\n",
    "    chess_column = chr(cols[i].item() + ord('a'))  # Map column index to chess notation (a-h)\n",
    "    chess_row = 8 - rows[i].item()  # Adjust row to match chess notation (8 is at the bottom)\n",
    "    print(f\"Max value: {max_values[i].item()} at {chess_column}{chess_row}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
